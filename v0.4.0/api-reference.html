
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>API reference &#8212; KerasLMU 0.4.0 docs</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #a8acaf;
  }
</style>
<!-- Google Tag Manager -->
<script>
 (function (w, d, s, l, i) {
   w[l] = w[l] || [];
   w[l].push({ "gtm.start": new Date().getTime(), event: "gtm.js" });
   var f = d.getElementsByTagName(s)[0],
       j = d.createElement(s),
       dl = l != "dataLayer" ? "&l=" + l : "";
   j.async = true;
   j.src = "https://www.googletagmanager.com/gtm.js?id=" + i + dl;
   f.parentNode.insertBefore(j, f);
 })(window, document, "script", "dataLayer", "GTM-KWCR2HN");
</script>
<!-- End Google Tag Manager -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
  
  
<script src="_static/underscore.js"></script>
  
  
<script src="_static/doctools.js"></script>
  
  
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="examples.html" />
    <link rel="prev" title="Basic usage" href="basic-usage.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai/">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/">What is Nengo?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/examples/">Examples</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">NengoGUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">NengoDL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">NengoSPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">NengoExtras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://www.nengo.ai/keras-spiking">KerasSpiking</a>
            <a class="dropdown-item" href="https://www.nengo.ai/pytorch-spiking">PyTorchSpiking</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">NengoFPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">NengoLoihi</a>
            <a class="dropdown-item" href="https://labs.nengo.ai/nengo-ocl/">NengoOCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">NengoSpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo-labs/nengo-mpi">NengoMPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation/"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people/"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school/"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing/"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications/"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos/"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct/"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa/">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/getting-started/"
            >Getting started</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="KerasLMU"
      />
    </a>
  </h3>
<form class="px-5 py-3 my-0 border-bottom" action="search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form><div class="p-5 toctree">
  
    <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic-usage.html">Basic usage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-keras_lmu.layers">LMU Layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="project.html">Project information</a></li>
</ul>

  
  </div>
  
  <form class="p-5 my-0 border-top">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option value="../api-reference.html">latest</option>
        
        
          
        <option selected>v0.4.0</option>
          
        
          
        <option value="../v0.3.1/api-reference.html">
          v0.3.1
        </option>
          
        
          
        <option value="../v0.3.0/api-reference.html">
          v0.3.0
        </option>
          
        
          
        <option value="../v0.2.0/api-reference.html">
          v0.2.0
        </option>
          
        
      </select>
    </div>
  </form>
  
</div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source" role="main">
              
              
  <div class="section" id="api-reference">
<span id="id1"></span><h1>API reference<a class="headerlink" href="#api-reference" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-keras_lmu.layers">
<span id="lmu-layers"></span><span id="api-reference-lc"></span><h2>LMU Layers<a class="headerlink" href="#module-keras_lmu.layers" title="Permalink to this headline">¶</a></h2>
<p>Core classes for the KerasLMU package.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#keras_lmu.LMUCell" title="keras_lmu.LMUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">keras_lmu.LMUCell</span></code></a></p></td>
<td><p>Implementation of LMU cell (to be used within Keras RNN wrapper).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#keras_lmu.LMU" title="keras_lmu.LMU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">keras_lmu.LMU</span></code></a></p></td>
<td><p>A layer of trainable low-dimensional delay systems.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#keras_lmu.layers.LMUFeedforward" title="keras_lmu.layers.LMUFeedforward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">keras_lmu.layers.LMUFeedforward</span></code></a></p></td>
<td><p>Layer class for the feedforward variant of the LMU.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="keras_lmu.LMUCell">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">keras_lmu.</span></code><code class="sig-name descname"><span class="pre">LMUCell</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L15-L397"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMUCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of LMU cell (to be used within Keras RNN wrapper).</p>
<p>In general, the LMU cell consists of two parts: a memory component (decomposing
the input signal using Legendre polynomials as a basis), and a hidden component
(learning nonlinear mappings from the memory component). <a class="reference internal" href="#r085f819d642b-1" id="id2">[1]</a> <a class="reference internal" href="#r085f819d642b-2" id="id3">[2]</a></p>
<p>This class processes one step within the whole time sequence input. Use the <code class="docutils literal notranslate"><span class="pre">LMU</span></code>
class to create a recurrent Keras layer to process the whole sequence. Calling
<code class="docutils literal notranslate"><span class="pre">LMU()</span></code> is equivalent to doing <code class="docutils literal notranslate"><span class="pre">RNN(LMUCell())</span></code>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>memory_d</strong><span class="classifier">int</span></dt><dd><p>Dimensionality of input to memory component.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int</span></dt><dd><p>The number of degrees in the transfer function of the LTI system used to
represent the sliding window of history. This parameter sets the number of
Legendre polynomials used to orthogonally represent the sliding window.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">float</span></dt><dd><p>The number of timesteps in the sliding window that is represented using the
LTI system. In this context, the sliding window represents a dynamic range of
data, of fixed size, that will be used to predict the value at the next time
step. If this value is smaller than the size of the input sequence, only that
number of steps will be represented at the time of prediction, however the
entire sequence will still be processed in order for information to be
projected to and from the hidden layer. If <code class="docutils literal notranslate"><span class="pre">trainable_theta</span></code> is enabled, then
theta will be updated during the course of training.</p>
</dd>
<dt><strong>hidden_cell</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></span></dt><dd><p>Keras Layer/RNNCell implementing the hidden component.</p>
</dd>
<dt><strong>trainable_theta</strong><span class="classifier">bool</span></dt><dd><p>If True, theta is learnt over the course of training. Otherwise, it is kept
constant.</p>
</dd>
<dt><strong>hidden_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the output of the hidden component back to the memory
component (default False).</p>
</dd>
<dt><strong>memory_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, add a learnable recurrent connection (in addition to the static
Legendre system) to the memory component (default False).</p>
</dd>
<dt><strong>input_to_hidden</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the input directly to the hidden component (in addition to
the connection from the memory component) (default False).</p>
</dd>
<dt><strong>discretizer</strong><span class="classifier">str</span></dt><dd><p>The method used to discretize the A and B matrices of the LMU. Current
options are “zoh” (short for Zero Order Hold) and “euler”.
“zoh” is more accurate, but training will be slower than “euler” if
<code class="docutils literal notranslate"><span class="pre">trainable_theta=True</span></code>. Note that a larger theta is needed when discretizing
using “euler” (a value that is larger than <code class="docutils literal notranslate"><span class="pre">4*order</span></code> is recommended).</p>
</dd>
<dt><strong>kernel_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for weights from input to memory/hidden component. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
no weights will be used, and the input size must match the memory/hidden size.</p>
</dd>
<dt><strong>recurrent_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> weights (if that connection is enabled).</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on input connections.</p>
</dd>
<dt><strong>recurrent_dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> connection.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r085f819d642b-1"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>Voelker and Eliasmith (2018). Improving spiking dynamical
networks: Accurate delays, higher-order synapses, and time cells.
Neural Computation, 30(3): 569-609.</p>
</dd>
<dt class="label" id="r085f819d642b-2"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>Voelker and Eliasmith. “Methods and systems for implementing
dynamic neural networks.” U.S. Patent Application No. 15/243,223.
Filing date: 2016-08-22.</p>
</dd>
</dl>
<dl class="py method">
<dt id="keras_lmu.layers.LMUCell.theta">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">theta</span></code><a class="headerlink" href="#keras_lmu.layers.LMUCell.theta" title="Permalink to this definition">¶</a></dt>
<dd><p>Value of the <code class="docutils literal notranslate"><span class="pre">theta</span></code> parameter.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">trainable_theta=True</span></code> this returns the trained value, not the initial
value passed in to the constructor.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMUCell.build">
<code class="sig-name descname"><span class="pre">build</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L215-L275"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMUCell.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the cell.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMUCell.call">
<code class="sig-name descname"><span class="pre">call</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L277-L354"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMUCell.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply this cell to inputs.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMUCell.reset_dropout_mask">
<code class="sig-name descname"><span class="pre">reset_dropout_mask</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L356-L360"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMUCell.reset_dropout_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset dropout mask for memory and hidden components.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMUCell.reset_recurrent_dropout_mask">
<code class="sig-name descname"><span class="pre">reset_recurrent_dropout_mask</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L362-L366"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMUCell.reset_recurrent_dropout_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset recurrent dropout mask for memory and hidden components.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMUCell.get_config">
<code class="sig-name descname"><span class="pre">get_config</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L368-L390"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMUCell.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Return config of layer (for serialization during model saving/loading).</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMUCell.from_config">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_config</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L392-L397"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMUCell.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model from serialized config.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="keras_lmu.LMU">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">keras_lmu.</span></code><code class="sig-name descname"><span class="pre">LMU</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L400-L625"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMU" title="Permalink to this definition">¶</a></dt>
<dd><p>A layer of trainable low-dimensional delay systems.</p>
<p>Each unit buffers its encoded input
by internally representing a low-dimensional
(i.e., compressed) version of the sliding window.</p>
<p>Nonlinear decodings of this representation,
expressed by the A and B matrices, provide
computations across the window, such as its
derivative, energy, median value, etc (<a class="reference internal" href="#rd58db2ef7c7f-1" id="id6">[1]</a>, <a class="reference internal" href="#rd58db2ef7c7f-2" id="id7">[2]</a>).
Note that these decoder matrices can span across
all of the units of an input sequence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>memory_d</strong><span class="classifier">int</span></dt><dd><p>Dimensionality of input to memory component.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int</span></dt><dd><p>The number of degrees in the transfer function of the LTI system used to
represent the sliding window of history. This parameter sets the number of
Legendre polynomials used to orthogonally represent the sliding window.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">float</span></dt><dd><p>The number of timesteps in the sliding window that is represented using the
LTI system. In this context, the sliding window represents a dynamic range of
data, of fixed size, that will be used to predict the value at the next time
step. If this value is smaller than the size of the input sequence, only that
number of steps will be represented at the time of prediction, however the
entire sequence will still be processed in order for information to be
projected to and from the hidden layer. If <code class="docutils literal notranslate"><span class="pre">trainable_theta</span></code> is enabled, then
theta will be updated during the course of training.</p>
</dd>
<dt><strong>hidden_cell</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></span></dt><dd><p>Keras Layer/RNNCell implementing the hidden component.</p>
</dd>
<dt><strong>trainable_theta</strong><span class="classifier">bool</span></dt><dd><p>If True, theta is learnt over the course of training. Otherwise, it is kept
constant.</p>
</dd>
<dt><strong>hidden_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the output of the hidden component back to the memory
component (default False).</p>
</dd>
<dt><strong>memory_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, add a learnable recurrent connection (in addition to the static
Legendre system) to the memory component (default False).</p>
</dd>
<dt><strong>input_to_hidden</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the input directly to the hidden component (in addition to
the connection from the memory component) (default False).</p>
</dd>
<dt><strong>discretizer</strong><span class="classifier">str</span></dt><dd><p>The method used to discretize the A and B matrices of the LMU. Current
options are “zoh” (short for Zero Order Hold) and “euler”.
“zoh” is more accurate, but training will be slower than “euler” if
<code class="docutils literal notranslate"><span class="pre">trainable_theta=True</span></code>. Note that a larger theta is needed when discretizing
using “euler” (a value that is larger than <code class="docutils literal notranslate"><span class="pre">4*order</span></code> is recommended).</p>
</dd>
<dt><strong>kernel_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for weights from input to memory/hidden component. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
no weights will be used, and the input size must match the memory/hidden size.</p>
</dd>
<dt><strong>recurrent_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> weights (if that connection is enabled).</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on input connections.</p>
</dd>
<dt><strong>recurrent_dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> connection.</p>
</dd>
<dt><strong>return_sequences</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, return the full output sequence. Otherwise, return just the last
output in the output sequence.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rd58db2ef7c7f-1"><span class="brackets"><a class="fn-backref" href="#id6">1</a></span></dt>
<dd><p>Voelker and Eliasmith (2018). Improving spiking dynamical
networks: Accurate delays, higher-order synapses, and time cells.
Neural Computation, 30(3): 569-609.</p>
</dd>
<dt class="label" id="rd58db2ef7c7f-2"><span class="brackets"><a class="fn-backref" href="#id7">2</a></span></dt>
<dd><p>Voelker and Eliasmith. “Methods and systems for implementing
dynamic neural networks.” U.S. Patent Application No. 15/243,223.
Filing date: 2016-08-22.</p>
</dd>
</dl>
<dl class="py method">
<dt id="keras_lmu.layers.LMU.theta">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">theta</span></code><a class="headerlink" href="#keras_lmu.layers.LMU.theta" title="Permalink to this definition">¶</a></dt>
<dd><p>Value of the <code class="docutils literal notranslate"><span class="pre">theta</span></code> parameter.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">trainable_theta=True</span></code> this returns the trained value, not the initial
value passed in to the constructor.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMU.build">
<code class="sig-name descname"><span class="pre">build</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L530-L580"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMU.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layer.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMU.call">
<code class="sig-name descname"><span class="pre">call</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L582-L593"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMU.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply this layer to inputs.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMU.get_config">
<code class="sig-name descname"><span class="pre">get_config</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L595-L618"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMU.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Return config of layer (for serialization during model saving/loading).</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.LMU.from_config">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_config</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L620-L625"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.LMU.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model from serialized config.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="keras_lmu.layers.LMUFeedforward">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">keras_lmu.layers.</span></code><code class="sig-name descname"><span class="pre">LMUFeedforward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L628-L924"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.layers.LMUFeedforward" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer class for the feedforward variant of the LMU.</p>
<p>This class assumes no recurrent connections are desired in the memory component.</p>
<p>Produces the output of the delay system by evaluating the convolution of the input
sequence with the impulse response from the LMU cell.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>memory_d</strong><span class="classifier">int</span></dt><dd><p>Dimensionality of input to memory component.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int</span></dt><dd><p>The number of degrees in the transfer function of the LTI system used to
represent the sliding window of history. This parameter sets the number of
Legendre polynomials used to orthogonally represent the sliding window.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">float</span></dt><dd><p>The number of timesteps in the sliding window that is represented using the
LTI system. In this context, the sliding window represents a dynamic range of
data, of fixed size, that will be used to predict the value at the next time
step. If this value is smaller than the size of the input sequence, only that
number of steps will be represented at the time of prediction, however the
entire sequence will still be processed in order for information to be
projected to and from the hidden layer.</p>
</dd>
<dt><strong>hidden_cell</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></span></dt><dd><p>Keras Layer implementing the hidden component.</p>
</dd>
<dt><strong>input_to_hidden</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the input directly to the hidden component (in addition to
the connection from the memory component) (default False).</p>
</dd>
<dt><strong>discretizer</strong><span class="classifier">str</span></dt><dd><p>The method used to discretize the A and B matrices of the LMU. Current
options are “zoh” (short for Zero Order Hold) and “euler”.
“zoh” is more accurate, but training will be slower than “euler” if
<code class="docutils literal notranslate"><span class="pre">trainable_theta=True</span></code>. Note that a larger theta is needed when discretizing
using “euler” (a value that is larger than <code class="docutils literal notranslate"><span class="pre">4*order</span></code> is recommended).</p>
</dd>
<dt><strong>kernel_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for weights from input to memory/hidden component. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
no weights will be used, and the input size must match the memory/hidden size.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on input connections.</p>
</dd>
<dt><strong>return_sequences</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, return the full output sequence. Otherwise, return just the last
output in the output sequence.</p>
</dd>
<dt><strong>conv_mode</strong><span class="classifier">“fft” or “raw”</span></dt><dd><p>The method for performing the inpulse response convolution. “fft” uses FFT
convolution (default). “raw” uses explicit convolution, which may be faster
for particular models on particular hardware.</p>
</dd>
<dt><strong>truncate_ir</strong><span class="classifier">float</span></dt><dd><p>The portion of the impulse response to truncate when using “raw”
convolution (see <code class="docutils literal notranslate"><span class="pre">conv_mode</span></code>). This is an approximate upper bound on the error
relative to the exact implementation. Smaller <code class="docutils literal notranslate"><span class="pre">theta</span></code> values result in more
truncated elements for a given value of <code class="docutils literal notranslate"><span class="pre">truncate_ir</span></code>, improving efficiency.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt id="keras_lmu.layers.LMUFeedforward.build">
<code class="sig-name descname"><span class="pre">build</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L736-L809"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.layers.LMUFeedforward.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layer.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.layers.LMUFeedforward.call">
<code class="sig-name descname"><span class="pre">call</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L811-L860"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.layers.LMUFeedforward.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply this layer to inputs.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.layers.LMUFeedforward.get_config">
<code class="sig-name descname"><span class="pre">get_config</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L897-L917"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.layers.LMUFeedforward.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Return config of layer (for serialization during model saving/loading).</p>
</dd></dl>

<dl class="py method">
<dt id="keras_lmu.layers.LMUFeedforward.from_config">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_config</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nengo/keras-lmu/blob/v0.4.0/keras_lmu/layers.py#L919-L924"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#keras_lmu.layers.LMUFeedforward.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model from serialized config.</p>
</dd></dl>

</dd></dl>

</div>
</div>


            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a class="no-hover-line" href="https://appliedbrainresearch.com">
      <img
        src="https://appliedbrainresearch.com/img/logo-blue-notext.svg"
        height="48"
      />
    </a>
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/examples/">Examples</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/getting-started/">Getting started</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>