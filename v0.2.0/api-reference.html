
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>API reference &#8212; NengoLMU 0.2.0 docs</title>
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #a8acaf;
  }
</style>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GT8XEDLTMJ"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'G-GT8XEDLTMJ');
</script>
<!-- End Google tag (gtag.js) -->

<!-- Matomo -->
<script>
 var _paq = window._paq = window._paq || [];
 _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
 _paq.push(["setCookieDomain", "*.appliedbrainresearch.com"]);
 _paq.push(["setDomains", ["*.appliedbrainresearch.com","*.edge.nengo.ai","*.forum.nengo.ai","*.labs.nengo.ai","*.nengo.ai"]]);
 _paq.push(["enableCrossDomainLinking"]);
 _paq.push(["setDoNotTrack", true]);
 _paq.push(['trackPageView']);
 _paq.push(['enableLinkTracking']);
 (function() {
   var u="https://appliedbrainresearch.matomo.cloud/";
   _paq.push(['setTrackerUrl', u+'matomo.php']);
   _paq.push(['setSiteId', '3']);
   var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
   g.async=true; g.src='//cdn.matomo.cloud/appliedbrainresearch.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
 })();
</script>
<!-- End Matomo Code -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
  
  
<script src="_static/underscore.js"></script>
  
  
<script src="_static/doctools.js"></script>
  
  
<script src="_static/language_data.js"></script>
  
  
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="examples.html" />
    <link rel="prev" title="Basic usage" href="basic-usage.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai/">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/">What is Nengo?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/examples/">Examples</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">NengoGUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">NengoDL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">NengoSPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">NengoExtras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://www.nengo.ai/keras-spiking">KerasSpiking</a>
            <a class="dropdown-item" href="https://www.nengo.ai/pytorch-spiking">PyTorchSpiking</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">NengoFPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">NengoLoihi</a>
            <a class="dropdown-item" href="https://labs.nengo.ai/nengo-ocl/">NengoOCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">NengoSpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo-labs/nengo-mpi">NengoMPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation/"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people/"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school/"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing/"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications/"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos/"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct/"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa/">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/getting-started/"
            >Getting started</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="NengoLMU"
      />
    </a>
  </h3>
<form class="px-5 py-3 my-0 border-bottom" action="search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form><div class="p-5 toctree">
  
    <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic-usage.html">Basic usage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-lmu.layers">LMU Layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="project.html">Project information</a></li>
</ul>

  
  </div>
  
  <form class="p-5 my-0 border-top">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option value="../api-reference.html">latest</option>
        
        
          
        <option selected>v0.2.0</option>
          
        
      </select>
    </div>
  </form>
  
</div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source" role="main">
              
              
  <div class="section" id="api-reference">
<span id="id1"></span><h1>API reference<a class="headerlink" href="#api-reference" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-lmu.layers">
<span id="lmu-layers"></span><span id="api-reference-lc"></span><h2>LMU Layers<a class="headerlink" href="#module-lmu.layers" title="Permalink to this headline">¶</a></h2>
<p>Core classes for the LMU package.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#lmu.LMUCell" title="lmu.LMUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lmu.LMUCell</span></code></a></p></td>
<td><p>Implementation of LMU cell (to be used within Keras RNN wrapper).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#lmu.LMU" title="lmu.LMU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lmu.LMU</span></code></a></p></td>
<td><p>A layer of trainable low-dimensional delay systems.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#lmu.LMUFFT" title="lmu.LMUFFT"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lmu.LMUFFT</span></code></a></p></td>
<td><p>Layer class for the FFT variant of the LMU.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="lmu.LMUCell">
<em class="property">class </em><code class="sig-prename descclassname">lmu.</code><code class="sig-name descname">LMUCell</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">memory_d</span></em>, <em class="sig-param"><span class="n">order</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">hidden_cell</span></em>, <em class="sig-param"><span class="n">hidden_to_memory</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">memory_to_memory</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">input_to_hidden</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">kernel_initializer</span><span class="o">=</span><span class="default_value">'glorot_uniform'</span></em>, <em class="sig-param"><span class="n">recurrent_initializer</span><span class="o">=</span><span class="default_value">'orthogonal'</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">recurrent_dropout</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L11-L277"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of LMU cell (to be used within Keras RNN wrapper).</p>
<p>In general, the LMU cell consists of two parts: a memory component (decomposing
the input signal using Legendre polynomials as a basis), and a hidden component
(learning nonlinear mappings from the memory component). <a class="reference internal" href="#r04ef3df16bdd-1" id="id2">[1]</a> <a class="reference internal" href="#r04ef3df16bdd-2" id="id3">[2]</a></p>
<p>This class processes one step within the whole time sequence input. Use the <code class="docutils literal notranslate"><span class="pre">LMU</span></code>
class to create a recurrent Keras layer to process the whole sequence. Calling
<code class="docutils literal notranslate"><span class="pre">LMU()</span></code> is equivalent to doing <code class="docutils literal notranslate"><span class="pre">RNN(LMUCell())</span></code>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>memory_d</strong><span class="classifier">int</span></dt><dd><p>Dimensionality of input to memory component.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int</span></dt><dd><p>The number of degrees in the transfer function of the LTI system used to
represent the sliding window of history. This parameter sets the number of
Legendre polynomials used to orthogonally represent the sliding window.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">int</span></dt><dd><p>The number of timesteps in the sliding window that is represented using the
LTI system. In this context, the sliding window represents a dynamic range of
data, of fixed size, that will be used to predict the value at the next time
step. If this value is smaller than the size of the input sequence, only that
number of steps will be represented at the time of
prediction, however the entire sequence will still be processed in order for
information to be projected to and from the hidden layer.</p>
</dd>
<dt><strong>hidden_cell</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></span></dt><dd><p>Keras Layer/RNNCell implementing the hidden component.</p>
</dd>
<dt><strong>hidden_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the output of the hidden component back to the memory
component (default False).</p>
</dd>
<dt><strong>memory_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, add a learnable recurrent connection (in addition to the static
Legendre system) to the memory component (default False).</p>
</dd>
<dt><strong>input_to_hidden</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the input directly to the hidden component (in addition to
the connection from the memory component) (default False).</p>
</dd>
<dt><strong>kernel_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for weights from input to memory/hidden component.</p>
</dd>
<dt><strong>recurrent_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> weights (if that connection is enabled).</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on input connections.</p>
</dd>
<dt><strong>recurrent_dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> connection.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r04ef3df16bdd-1"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>Voelker and Eliasmith (2018). Improving spiking dynamical
networks: Accurate delays, higher-order synapses, and time cells.
Neural Computation, 30(3): 569-609.</p>
</dd>
<dt class="label" id="r04ef3df16bdd-2"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>Voelker and Eliasmith. “Methods and systems for implementing
dynamic neural networks.” U.S. Patent Application No. 15/243,223.
Filing date: 2016-08-22.</p>
</dd>
</dl>
<dl class="py method">
<dt id="lmu.LMUCell.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_shape</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L132-L187"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUCell.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the cell.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMUCell.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">states</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L189-L248"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUCell.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply this cell to inputs.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMUCell.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L250-L270"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUCell.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Return config of layer (for serialization during model saving/loading).</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMUCell.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L272-L277"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUCell.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model from serialized config.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lmu.LMU">
<em class="property">class </em><code class="sig-prename descclassname">lmu.</code><code class="sig-name descname">LMU</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">memory_d</span></em>, <em class="sig-param"><span class="n">order</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">hidden_cell</span></em>, <em class="sig-param"><span class="n">hidden_to_memory</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">memory_to_memory</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">input_to_hidden</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">kernel_initializer</span><span class="o">=</span><span class="default_value">'glorot_uniform'</span></em>, <em class="sig-param"><span class="n">recurrent_initializer</span><span class="o">=</span><span class="default_value">'orthogonal'</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">recurrent_dropout</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">return_sequences</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L280-L469"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMU" title="Permalink to this definition">¶</a></dt>
<dd><p>A layer of trainable low-dimensional delay systems.</p>
<p>Each unit buffers its encoded input
by internally representing a low-dimensional
(i.e., compressed) version of the sliding window.</p>
<p>Nonlinear decodings of this representation,
expressed by the A and B matrices, provide
computations across the window, such as its
derivative, energy, median value, etc (<a class="reference internal" href="#r2067a8638803-1" id="id6">[1]</a>, <a class="reference internal" href="#r2067a8638803-2" id="id7">[2]</a>).
Note that these decoder matrices can span across
all of the units of an input sequence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>memory_d</strong><span class="classifier">int</span></dt><dd><p>Dimensionality of input to memory component.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int</span></dt><dd><p>The number of degrees in the transfer function of the LTI system used to
represent the sliding window of history. This parameter sets the number of
Legendre polynomials used to orthogonally represent the sliding window.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">int</span></dt><dd><p>The number of timesteps in the sliding window that is represented using the
LTI system. In this context, the sliding window represents a dynamic range of
data, of fixed size, that will be used to predict the value at the next time
step. If this value is smaller than the size of the input sequence, only that
number of steps will be represented at the time of
prediction, however the entire sequence will still be processed in order for
information to be projected to and from the hidden layer.</p>
</dd>
<dt><strong>hidden_cell</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></span></dt><dd><p>Keras Layer/RNNCell implementing the hidden component.</p>
</dd>
<dt><strong>hidden_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the output of the hidden component back to the memory
component (default False).</p>
</dd>
<dt><strong>memory_to_memory</strong><span class="classifier">bool</span></dt><dd><p>If True, add a learnable recurrent connection (in addition to the static
Legendre system) to the memory component (default False).</p>
</dd>
<dt><strong>input_to_hidden</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the input directly to the hidden component (in addition to
the connection from the memory component) (default False).</p>
</dd>
<dt><strong>kernel_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for weights from input to memory/hidden component.</p>
</dd>
<dt><strong>recurrent_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> weights (if that connection is enabled).</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on input connections.</p>
</dd>
<dt><strong>recurrent_dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on <code class="docutils literal notranslate"><span class="pre">memory_to_memory</span></code> connection.</p>
</dd>
<dt><strong>return_sequences</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, return the full output sequence. Otherwise, return just the last
output in the output sequence.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r2067a8638803-1"><span class="brackets"><a class="fn-backref" href="#id6">1</a></span></dt>
<dd><p>Voelker and Eliasmith (2018). Improving spiking dynamical
networks: Accurate delays, higher-order synapses, and time cells.
Neural Computation, 30(3): 569-609.</p>
</dd>
<dt class="label" id="r2067a8638803-2"><span class="brackets"><a class="fn-backref" href="#id7">2</a></span></dt>
<dd><p>Voelker and Eliasmith. “Methods and systems for implementing
dynamic neural networks.” U.S. Patent Application No. 15/243,223.
Filing date: 2016-08-22.</p>
</dd>
</dl>
<dl class="py method">
<dt id="lmu.LMU.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_shapes</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L407-L423"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMU.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layer.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMU.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L425-L439"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMU.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply this layer to inputs.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMU.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L441-L462"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMU.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Return config of layer (for serialization during model saving/loading).</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMU.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L464-L469"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMU.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model from serialized config.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lmu.LMUFFT">
<em class="property">class </em><code class="sig-prename descclassname">lmu.</code><code class="sig-name descname">LMUFFT</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">memory_d</span></em>, <em class="sig-param"><span class="n">order</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">hidden_cell</span></em>, <em class="sig-param"><span class="n">input_to_hidden</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">kernel_initializer</span><span class="o">=</span><span class="default_value">'glorot_uniform'</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">return_sequences</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L472-L679"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUFFT" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer class for the FFT variant of the LMU.</p>
<p>This class assumes no recurrent connections are desired in the memory component.</p>
<p>Produces the output of the delay system by evaluating the convolution of the input
sequence with the impulse response from the LMU cell. The convolution operation is
calculated using the fast Fourier transform (FFT).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>memory_d</strong><span class="classifier">int</span></dt><dd><p>Dimensionality of input to memory component.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int</span></dt><dd><p>The number of degrees in the transfer function of the LTI system used to
represent the sliding window of history. This parameter sets the number of
Legendre polynomials used to orthogonally represent the sliding window.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">int</span></dt><dd><p>The number of timesteps in the sliding window that is represented using the
LTI system. In this context, the sliding window represents a dynamic range of
data, of fixed size, that will be used to predict the value at the next time
step. If this value is smaller than the size of the input sequence, only that
number of steps will be represented at the time of
prediction, however the entire sequence will still be processed in order for
information to be projected to and from the hidden layer.</p>
</dd>
<dt><strong>hidden_cell</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></span></dt><dd><p>Keras Layer implementing the hidden component.</p>
</dd>
<dt><strong>input_to_hidden</strong><span class="classifier">bool</span></dt><dd><p>If True, connect the input directly to the hidden component (in addition to
the connection from the memory component) (default False).</p>
</dd>
<dt><strong>kernel_initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">tf.initializers.Initializer</span></code></span></dt><dd><p>Initializer for weights from input to memory/hidden component.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate on input connections.</p>
</dd>
<dt><strong>return_sequences</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, return the full output sequence. Otherwise, return just the last
output in the output sequence.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt id="lmu.LMUFFT.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_shape</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L556-L595"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUFFT.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the layer.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMUFFT.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L597-L653"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUFFT.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply this layer to inputs.</p>
<p class="rubric">Notes</p>
<p>This method should not be called manually; rather, use the implicit layer
callable behaviour (like <code class="docutils literal notranslate"><span class="pre">my_layer(inputs)</span></code>), which will apply this method
with some additional bookkeeping.</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMUFFT.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L655-L672"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUFFT.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Return config of layer (for serialization during model saving/loading).</p>
</dd></dl>

<dl class="py method">
<dt id="lmu.LMUFFT.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">config</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/abr/lmu/blob/v0.2.0/lmu/layers.py#L674-L679"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lmu.LMUFFT.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model from serialized config.</p>
</dd></dl>

</dd></dl>

</div>
</div>


            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a class="no-hover-line" href="https://appliedbrainresearch.com">
      <img
        src="https://appliedbrainresearch.com/img/logo-blue-notext.svg"
        height="48"
      />
    </a>
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/examples/">Examples</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/getting-started/">Getting started</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>